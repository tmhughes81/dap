{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disputed Author Project (dap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      author         title                                               text\n",
      "0      Plato     Symposium  This is the text of the Symposium.  It is just...\n",
      "1  Aristotle  Nico. Ethics  This is a second text, by a different author. ...\n",
      "2   Xenophon       Apology  This is a third text.  It is also just used fo...\n"
     ]
    }
   ],
   "source": [
    "# Sample corpus for testing\n",
    "d1 = {\n",
    "    'author': 'Plato',\n",
    "    'title': 'Symposium',\n",
    "    'text': 'This is the text of the Symposium.  It is just an example for testing.'\n",
    "}\n",
    "\n",
    "d2 = {\n",
    "    'author': 'Aristotle',\n",
    "    'title': 'Nico. Ethics',\n",
    "    'text': 'This is a second text, by a different author.  It is still just for testing.'\n",
    "}\n",
    "\n",
    "d3 = {\n",
    "    'author': 'Xenophon',\n",
    "    'title': 'Apology',\n",
    "    'text': 'This is a third text.  It is also just used for testing.  Do not get excited.'\n",
    "}\n",
    "\n",
    "dataset = pd.DataFrame(data=[d1, d2, d3], columns=['author', 'title', 'text'])\n",
    "#dataset = dataset.set_index('title')\n",
    "print dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "\n",
    "vec.fit(dataset['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_idf_vec = vec.transform(dataset['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.29503437,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.29503437,  0.        ,  0.17425205,  0.        ,\n",
       "         0.3485041 ,  0.17425205,  0.17425205,  0.        ,  0.29503437,\n",
       "         0.        ,  0.        ,  0.29503437,  0.17425205,  0.17425205,\n",
       "         0.59006874,  0.        ,  0.17425205,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.34323401,  0.34323401,  0.34323401,\n",
       "         0.        ,  0.        ,  0.        ,  0.20271953,  0.        ,\n",
       "         0.40543907,  0.20271953,  0.20271953,  0.        ,  0.        ,\n",
       "         0.34323401,  0.34323401,  0.        ,  0.20271953,  0.20271953,\n",
       "         0.        ,  0.        ,  0.20271953,  0.        ],\n",
       "       [ 0.30877917,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.30877917,  0.        ,  0.30877917,  0.18236995,  0.30877917,\n",
       "         0.3647399 ,  0.18236995,  0.18236995,  0.30877917,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.18236995,  0.18236995,\n",
       "         0.        ,  0.30877917,  0.18236995,  0.30877917]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_idf_df = pd.DataFrame(columns=vec.get_feature_names(), data=tf_idf_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tf_idf_df['title'] = dataset['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_df = dataset.join(tf_idf_df, lsuffix='_meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  author_meta         title  \\\n",
      "0       Plato     Symposium   \n",
      "1   Aristotle  Nico. Ethics   \n",
      "2    Xenophon       Apology   \n",
      "\n",
      "                                           text_meta      also        an  \\\n",
      "0  This is the text of the Symposium.  It is just...  0.000000  0.295034   \n",
      "1  This is a second text, by a different author. ...  0.000000  0.000000   \n",
      "2  This is a third text.  It is also just used fo...  0.308779  0.000000   \n",
      "\n",
      "     author        by  different        do   example    ...           of  \\\n",
      "0  0.000000  0.000000   0.000000  0.000000  0.295034    ...     0.295034   \n",
      "1  0.343234  0.343234   0.343234  0.000000  0.000000    ...     0.000000   \n",
      "2  0.000000  0.000000   0.000000  0.308779  0.000000    ...     0.000000   \n",
      "\n",
      "     second     still  symposium   testing      text       the     third  \\\n",
      "0  0.000000  0.000000   0.295034  0.174252  0.174252  0.590069  0.000000   \n",
      "1  0.343234  0.343234   0.000000  0.202720  0.202720  0.000000  0.000000   \n",
      "2  0.000000  0.000000   0.000000  0.182370  0.182370  0.000000  0.308779   \n",
      "\n",
      "       this      used  \n",
      "0  0.174252  0.000000  \n",
      "1  0.202720  0.000000  \n",
      "2  0.182370  0.308779  \n",
      "\n",
      "[3 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_df = cluster_df.set_index('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-c681b85f46f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author_meta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'author_meta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0my_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mX_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, crit, axis)\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m             new_axis = axis_values[\n\u001b[0;32m-> 1535\u001b[0;31m                 np.asarray([bool(crit(label)) for label in axis_values])]\n\u001b[0m\u001b[1;32m   1536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m             \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Series' object is not callable"
     ]
    }
   ],
   "source": [
    "y_set = cluster_df.select(cluster_df['author_meta'])\n",
    "X_set = cluster_df.drop('author_meta', 1)\n",
    "\n",
    "print y_set\n",
    "print X_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
